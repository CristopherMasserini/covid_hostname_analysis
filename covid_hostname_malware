"""
Author: Cristopher Masserini

Can be found at: https://github.com/CristopherMasserini/covid_hostname_analysis

A project that takes a file of hostnames that have a reference to COVID-19 and attempts to separate the malicious
from the valid. The goal here was to get a viable package available as quickly as possible to help mitigate the affect
of opportunistic attackers.

Due to what is being used from these packages, the newest versions of these packages and of Python is required
"""

# ===Imports===
import requests
from datetime import datetime
import pandas as pd
import whois
import subprocess


# ===Processing===

# This takes the date and time, combines them and converts it into seconds since the Epoch for easy calculation
# Also puts the hostnames into its list
# date_to_start is the date where you want to start the processing. Useful this is being more than once. This way,
# You do not need to process all the data each time you want to update your data
def processing(text_list: str, date_to_start: str) -> pd.DataFrame:
    seconds_of_record = list()  # The date and time of the hostname creation using Epoch time
    dates_of_record = list()  # The date and time of the hostname creation using date time
    hostnames = list()  # The hostname
    # Ignores the description before the data starts
    start_index = text_list.index("date,time,hostname")
    for record in text_list[start_index + 1:]:
        try:
            # Splits the record into date, time, and hostname
            record_list = record.split(',')
            record_datetime_str = record_list[0] + " " + record_list[1]  # Concatenates the date and time
            hostname = record_list[2]  # The host name
            record_datetime = datetime.strptime(record_datetime_str, '%Y-%m-%d %H:%M:%S.%f')  # Converts to datetime
            start_date = datetime.strptime(date_to_start, '%Y-%m-%d %H:%M:%S.%f')  # Converts start date to datetime
            record_datetime_seconds = record_datetime.timestamp()  # Puts seconds since Epoch
            start_date_seconds = start_date.timestamp()  # Puts seconds since Epoch
            if record_datetime_seconds >= start_date_seconds:
                seconds_of_record.append(record_datetime_seconds)  # Puts the creation time into a list
                dates_of_record.append(record_datetime)  # Puts the creation time into a list
                hostnames.append(hostname)  # Puts the hostname into a list
        except IndexError:  # Got to the last record in the list
            pass

    # Puts the seconds since Epoch and hostname into a data frame. This is used so it can be sorted by the seconds.
    # This is because at the time of writing this code, not all the data is sorted according to date and time correctly.
    pd.options.display.float_format = '{:10f}'.format
    data = {"Hostname Creation Date": dates_of_record, "Hostname Creation Time": seconds_of_record,
            "Hostname": hostnames}
    df = pd.DataFrame(data)
    df = df.sort_values(by=["Hostname Creation Time"])
    df.index = range(len(df))  # Resets the indexing after the the sorting
    return df


# ===Scoring===

# Create a score. So depending on the time diff column and the amount of time since the base domain was created,
# the hostname will get a score. Smaller the score, the higher the risk of being malicious.
# For time difference: less than one second gets a score of 1, between one and 5 seconds gets a score of 5,
# Between 5 and 10 seconds gets a score of 10, above 10 seconds gets a score of 15
# I give an intermediate score of 7 for time that equal zero. This is because of the issue that arises outlined
# In the file of the first hostnames with the same time for date and time. Since it is not known, time cannot be
# An overwhelming factor in score, right now. Can be fixed in the future
def creation_scoring(df: pd.DataFrame) -> pd.DataFrame:
    # This calculates the difference in time that a host name was created since the last host name creation time.
    time_since_last = list()  # Used to see time between hostname creations
    score = list()  # Used to score the record
    for i in range(0, len(df.loc[:, "Hostname Creation Time"])):
        print(i)
        time_of_record = df.loc[:, "Hostname Creation Time"]
        time = 0.0
        if i == 0:
            time_since_last.append(time)
        else:
            try:
                time = time_of_record[i] - time_of_record[i - 1]
                time_since_last.append(time)
            except IndexError:
                time = time_of_record[i] - time_of_record[i - 1]
                time_since_last.append(time)

        # The actual scoring
        if time == 0:
            score.append(7)
        elif 0 < time <= 1:
            score.append(1)
        elif 1 < time <= 5:
            score.append(5)
        elif 5 < time <= 10:
            score.append(10)
        else:
            score.append(15)

    # Adds the difference in time and score to the data frame
    df.loc[:, "Time diff"] = time_since_last
    df.loc[:, "Time Score"] = score

    # Saving an intermediate file
    write_csv(df, r'HostnameData_Intermediate1.csv', "write")
    return df


# Gives a score for how ling the base domain has been active. For instance, any hostname with duke.edu base domain
# Will come up with a creation date time of 1986-06-02 00:00:00.
# Less than one year, score is 1, between one year and two years gets a score of 5
# Between two year and five years gets a score of 10, and greater than 5 years gets a score of 10
# Because whois library does not recognize some TLD, like .pt which is the portugal country code TLD,
# Any hostnames with this problem get an intermediate score of 7
# If a creation date is not listed or wrong format, given an intermediate score of 7
# Other errors are given a score of 1
def base_domain_scoring(df: pd.DataFrame) -> pd.DataFrame:
    # Assuming a 365 day year and no leap seconds, a good enough calculation
    # score = list(df.loc[:, "Score"])
    score_new = list()

    # Amount of time to be used in the scoring
    seconds_in_year = 31536000
    now = datetime.utcnow().timestamp()
    one_year_ago = now - seconds_in_year
    two_years_ago = now - (2 * seconds_in_year)
    five_years_ago = now - (5 * seconds_in_year)

    names = list(df.loc[:, "Hostname"])
    hostname_creation_times = list(df.loc[:, "Hostname Creation Time"])
    for i in range(0, len(names)):
        print("Part 2: {}".format(i))
        name = names[i]
        try:
            hostname_creation_time = hostname_creation_times[i]

            # A lot of the hostnames on the list are already base domains, so do not need to look those up
            # Just a way to save time, otherwise it has a really long run time
            if len(name.split('.')) > 2:
                hostname_creation_time = whois.query(name).creation_date.timestamp()

            # The scoring for time since the base domain was created.
            if hostname_creation_time > one_year_ago:
                score_new.append(1)
            elif two_years_ago < hostname_creation_time <= one_year_ago:
                score_new.append(5)
            elif five_years_ago < hostname_creation_time <= two_years_ago:
                score_new.append(10)
            else:
                score_new.append(15)
        except AttributeError:
            # Some of the hostnames don't give a creation date
            score_new.append(7)
        except UnicodeDecodeError:
            # Some of the hostnames have non-unicode names
            print('UnicodeDecodeError = {}'.format(name))
            score_new.append(1)
        except KeyError:
            print('Key Error = {}'.format(name))
            score_new.append(1)
        except whois.exceptions.WhoisCommandFailed:
            # Some hostnames show this for unknown reasons
            print('whois.exceptions.WhoisCommandFailed = {}'.format(name))
            score_new.append(1)
        except whois.exceptions.FailedParsingWhoisOutput:
            # When not running from an IDE, some hostnames show this error
            print('whois.exceptions.FailedParsingWhoisOutput = {}'.format(name))
            score_new.append(1)
        except whois.exceptions.UnknownDateFormat:
            # Some of the hostnames don't give a creation date in correct format
            print('whois.exceptions.UnknownDateFormat = {}'.format(name))
            score_new.append(7)
        except whois.exceptions.UnknownTld:
            # This is done for the problem described above
            score_new.append(7)

    df.loc[:, "Base Domain Score"] = score_new

    # Saving an intermediate file
    write_csv(df, r'HostnameData_Intermediate2.csv', "write")

    return df


# Add the IP Address of the hostname to the data frame.
# This can be used to see which hostnames all have the same IP Address
# Many hostnames all with the same IP can be a sign of a phishy domain
def ip_inclusion(df: pd.DataFrame) -> pd.DataFrame:
    # For IP Address lookup
    global ip_distinct
    global ip_count

    ip_list = list()
    names = list(df.loc[:, "Hostname"])
    for i in range(0, len(names)):
        print("Part 3: {}".format(i))
        # Looks up the IP Address using nslookup
        cmd = 'nslookup {} | grep Address: |grep -v -e "#"'.format(names[i])
        ps = subprocess.Popen(cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        output = ps.communicate()[0]
        ip = output.split('\n')[0][9:]
        ip_list.append(ip)

        # Adds the IP to the data frame
        if ip not in ip_distinct:
            ip_distinct.append(ip)
            ip_count.append(1)
        else:
            _ = ip_distinct.index(ip)
            count = ip_count[_] + 1
            ip_count[_] = count

    df.loc[:, "IP Addresses"] = ip_list

    # Saving an intermediate file
    write_csv(df, r'HostnameData_Intermediate3.csv', "write")

    return df


# Calculates a final score based off of the base domain score, the creation time score,
# and how many times the same IP address came up in the file.
# This also puts the scoring in line with industry standard.
def final_score(df: pd.DataFrame) -> pd.DataFrame:
    global ip_distinct
    global ip_count
    end_score = list()
    time_score = list(df.loc[:, "Time Score"])
    domain_score = list(df.loc[:, "Base Domain Score"])
    ip = list(df.loc[:, "IP Addresses"])

    # If IP only comes up one time, deemed the safest
    # 2 or 3 times is acceptable but sometimes worrisome
    # More than 3 times, this is highest risk with the exception of no IP given, which is given the lowest risk rating
    for i in range(0, len(time_score)):
        score_1 = time_score[i] + domain_score[i]
        print("IP Score: {}".format(i))

        # The end scores are made to be out of 100, inline with industry standards
        _ = ip_count[ip_distinct.index(ip[i])]
        if _ == 1:
            end_score.append(100 - (score_1 + 10))
        elif 2 <= _ <= 3:
            end_score.append(100 - (score_1 + 5))
        else:
            if ip == "":
                end_score.append(100 - (score_1 + 10))
            else:
                end_score.append(100 - (score_1 + 1))

    df.loc[:, "Final Score"] = end_score
    return df


# ===Writing to a CSV===

# Writes to a csv. Either writing a new file or appending
# df is data to be added
# name is name of file
# selection is if it is to be appended or a new file
def write_csv(df: pd.DataFrame, name: str, selection: str):
    if selection == "append":
        df.to_csv(name, mode='a', header=False, index=False)
    else:
        df.to_csv(name, index=False)


if __name__ == '__main__':
    # Getting the data from the link
    # This then splits the file into individual strings at new line characters
    link = 'https://1984.sh/covid19-domains-feed.txt'
    f = requests.get(link)
    link_text = f.text.split('\n')

    # The date and time to start at
    # 2020-03-14 15:11:20.684411 is the very beginning of the file
    initial_date = "2020-03-14 15:11:20.684411"

    # Lists for the IPs needed
    ip_distinct = list()
    ip_count = list()

    # Calling the functions to create the data frame
    initial_df = creation_scoring(processing(link_text, initial_date))
    df_base_domain = base_domain_scoring(initial_df)
    df_with_ips = ip_inclusion(df_base_domain)
    final_df = final_score(df_with_ips)

    # Creating the CSV
    write_csv(final_df, r'HostnameData.csv', "write")
